import re

TOKEN_SPEC = [
    ('NUMBER',   r'\d+'),                 # ìˆ«ì (ì˜ˆ: 123)               
    ('LPAREN',   r'\('),                 # (
    ('RPAREN',   r'\)'),  
    ('DOT',      r'\.'),
    ('OPERATOR', r'==|!=|<=|>=|\|\||&&|[+\-*/<>]'),
    ('COMMA',    r','),  
    ('SEMICOLON',r';'),                  # ;
    ('SKIP',     r'[ \t]+'),             # ê³µë°± (ë¬´ì‹œ)
    ('NEWLINE',  r'\n'),                 # ì¤„ë°”ê¿ˆ
    ('LAMBDA',   r'ì„ì‹œ'),
    ('COLON',     r':'),
    ('STRING',    r'"[^"]*"'),
    ('IMPORT',   r'ì†Œí™˜!'),
    ('TUKGUM',   r'íŠ¹ê²€'),
    ('COMMENT',  r'ğŸ–•[^\n]*'),
    ('IDENT',    r'(?!ì„ì‹œ|ì†Œí™˜!|íŠ¹ê²€)[ê°€-í£ã„±-ã…ã…-ã…£a-zA-Z_][ê°€-í£ã„±-ã…ã…-ã…£a-zA-Z0-9_]*'),  # í´ë˜ìŠ¤
]

# ì •ê·œì‹ í•˜ë‚˜ë¡œ ê²°í•©
token_regex = '|'.join(f'(?P<{name}>{pattern})' for name, pattern in TOKEN_SPEC)
master_pat = re.compile(token_regex)

def lexer(code):
    tokens = []
    line_num = 1
    for mo in master_pat.finditer(code):
        kind = mo.lastgroup
        value = mo.group()
        if kind == 'COMMENT':
            continue
        elif kind == 'NUMBER':
            value = int(value)
            tokens.append((kind, value))
        elif kind == 'NEWLINE':
            line_num += 1
        elif kind == 'SKIP':
            continue
        else:
            tokens.append((kind, value))
    return tokens
